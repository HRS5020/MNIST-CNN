{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDL_ex6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1Wsn_jdc-bd",
        "colab_type": "text"
      },
      "source": [
        "# IDL Assignment 3\n",
        "Members:\n",
        "\n",
        "Harsh Solanki (226254)\n",
        "\n",
        "Vaibhav Bhatia (226222)\n",
        "\n",
        "# Part 1 : MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gpnezQV374B",
        "colab_type": "code",
        "outputId": "e4ce29f4-cb72-4aca-b6c4-48d31abf1157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "tf.__version__\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxr0I2_C4Jms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "\n",
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "data = data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(10000)\n",
        "\n",
        "train_steps = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiAVi-pw4PoI",
        "colab_type": "code",
        "outputId": "e794dd3b-ec17-4396-d227-602a126129d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "visible = tf.keras.layers.Input(shape=(28,28,1))\n",
        "conv1 = Conv2D(32, kernel_size=7, activation='relu')(visible)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, kernel_size=4, activation='relu')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "flat = Flatten()(pool2)\n",
        "hidden1 = Dense(100, activation='relu')(flat)\n",
        "hidden1 = Dropout(0.2)(hidden1)\n",
        "output = Dense(10, activation='sigmoid')(hidden1)\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "\n",
        "# Adam makes things much smoother\n",
        "opt = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])\n",
        "varis = model.trainable_variables\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 22, 22, 32)        1600      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 64)          32832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               102500    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 137,942\n",
            "Trainable params: 137,942\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L82HS4Hs4qae",
        "colab_type": "code",
        "outputId": "ccbcc6c6-3831-4327-f52f-f74cb13c2dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# this basically hasn't changed\n",
        "for step, (img_batch, lbl_batch) in enumerate(data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(img_batch)\n",
        "        xent = loss_fn(lbl_batch, logits)\n",
        "\n",
        "    grads = tape.gradient(xent, varis)\n",
        "      \n",
        "    opt.apply_gradients(zip(grads, varis))\n",
        "    \n",
        "    if not step % 100:\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
        "                             tf.float32))\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.3036880493164062 Accuracy: 0.0859375\n",
            "Loss: 1.5713406801223755 Accuracy: 0.890625\n",
            "Loss: 1.5020711421966553 Accuracy: 0.9609375\n",
            "Loss: 1.4846410751342773 Accuracy: 0.984375\n",
            "Loss: 1.4801596403121948 Accuracy: 0.984375\n",
            "Loss: 1.4793096780776978 Accuracy: 0.9765625\n",
            "Loss: 1.500380516052246 Accuracy: 0.9609375\n",
            "Loss: 1.4978487491607666 Accuracy: 0.9609375\n",
            "Loss: 1.5029799938201904 Accuracy: 0.96875\n",
            "Loss: 1.4759957790374756 Accuracy: 0.984375\n",
            "Loss: 1.4984683990478516 Accuracy: 0.9609375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaMa4zXM6Mxg",
        "colab_type": "code",
        "outputId": "66ae9ce8-6b9d-493f-af96-e1b75000c144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "big_test_batch = next(iter(test_data))\n",
        "test_preds = tf.argmax(model(big_test_batch[0]), axis=1,\n",
        "                       output_type=tf.int32)\n",
        "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, big_test_batch[1]),\n",
        "                             tf.float32))\n",
        "print(acc)\n",
        "\n",
        "# model.evaluate(test_images, test_labels, batch_size=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.9812, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB0OG0HJWhZ2",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 : CIFAR Implementation\n",
        "\n",
        "Same archihtecture used in MNIST doesn't work.\n",
        "\n",
        "Pending: Try different architectures and analyse the modifications with tensorboard\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_c8jSfWB8hC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar = tf.keras.datasets.cifar10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()\n",
        "\n",
        "\n",
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "data = data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(10000)\n",
        "\n",
        "\n",
        "train_labels = train_labels.reshape((-1))\n",
        "test_labels = test_labels.reshape((-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSAK00EbWRIG",
        "colab_type": "code",
        "outputId": "c382d004-91bb-4ef2-f15c-56c82197178c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "visible = tf.keras.layers.Input(shape=(32,32,3))\n",
        "conv1 = Conv2D(32, kernel_size=7, activation='relu')(visible)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, kernel_size=4, activation='relu')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, kernel_size=(3,3), activation='relu')(pool2)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "flat = Flatten()(pool3)\n",
        "hidden1 = Dense(100, activation='relu')(flat)\n",
        "hidden1 = Dropout(0.2)(hidden1)\n",
        "output = Dense(10, activation='sigmoid')(hidden1)\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "\n",
        "# Adam makes things much smoother\n",
        "opt = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])\n",
        "varis = model.trainable_variables"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 26, 26, 32)        4736      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 10, 10, 64)        32832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               12900     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 125,334\n",
            "Trainable params: 125,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRI4q29QW1tB",
        "colab_type": "code",
        "outputId": "ee079e15-2d8d-40ad-9ebb-9d0e2dfe95af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "for step, (img_batch, lbl_batch) in enumerate(data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(img_batch)\n",
        "        xent = loss_fn(lbl_batch, logits)\n",
        "\n",
        "    grads = tape.gradient(xent, varis)\n",
        "      \n",
        "    model.optimizer.apply_gradients(zip(grads, varis))\n",
        "    \n",
        "    if not step % 100:\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
        "                             tf.float32))\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "\n",
        "big_test_batch = next(iter(test_data))\n",
        "test_preds = tf.argmax(model(big_test_batch[0]), axis=1,\n",
        "                       output_type=tf.int32)\n",
        "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, big_test_batch[1]),\n",
        "                             tf.float32))\n",
        "print(acc)\n",
        "\n",
        "# model.evaluate(test_images, test_labels, batch_size=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.3025529384613037 Accuracy: 0.107666015625\n",
            "Loss: 2.0865719318389893 Accuracy: 0.106689453125\n",
            "Loss: 1.9736580848693848 Accuracy: 0.099365234375\n",
            "Loss: 2.0411219596862793 Accuracy: 0.08984375\n",
            "Loss: 1.9038348197937012 Accuracy: 0.115234375\n",
            "Loss: 1.9602935314178467 Accuracy: 0.1043701171875\n",
            "Loss: 1.982086420059204 Accuracy: 0.1048583984375\n",
            "Loss: 1.9040179252624512 Accuracy: 0.0906982421875\n",
            "Loss: 1.9058732986450195 Accuracy: 0.10345458984375\n",
            "Loss: 1.9699639081954956 Accuracy: 0.0953369140625\n",
            "Loss: 1.8816304206848145 Accuracy: 0.098876953125\n",
            "tf.Tensor(0.1, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}